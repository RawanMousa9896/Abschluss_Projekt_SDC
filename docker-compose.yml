version: '3.9'

services:
  model-server:
    image: tensorflow/serving
    command:
      - --model_name=animal_classifier
      - --model_base_path=/models/animal_classifier
      - --rest_api_port=8501
    ports:
      - 8501:8501
    volumes:
      - ./models:/models  # Bindet den lokalen models-Ordner in den Container ein

  frontend:
    image: python:3.9
    volumes:
      - ./frontend:/app
    working_dir: /app
    command: bash -c "pip install -r requirements.txt && streamlit run app.py --server.port 8502"
    ports:
      - "8502:8502"
    depends_on:
      - model-server
